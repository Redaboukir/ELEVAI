import pandas as pd
import joblib
import mysql.connector
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest

print("ğŸš€ DÃ‰MARRAGE TRAIN ML")

# ğŸ”¹ Connexion MySQL
conn = mysql.connector.connect(
    host="localhost",
    user="root",
    password="",
    database="elevai"
)

# ğŸ”¹ Dataset rÃ©el depuis la base
query = """
SELECT
  d.sommeil_h,
  d.pas,
  d.sport_min,
  d.calories,
  d.humeur_0_5,
  d.stress_0_5,
  d.fc_repos,
  a.score
FROM daily_data d
JOIN analysis_results a
  ON d.user_id = a.user_id
 AND d.date = a.date
"""


print("ğŸ“¥ Lecture donnÃ©es MySQL...")
df = pd.read_sql(query, conn)

# ğŸ”¹ Export dataset (POUR LE PROF âœ…)
df.to_csv("dataset_export.csv", index=False)

print("ğŸ“Š Lignes chargÃ©es :", len(df))

if df.empty:
    raise Exception("âŒ Aucune donnÃ©e pour entraÃ®ner le ML")

# ğŸ”¹ Features
features = [
    "sommeil_h",
    "pas",
    "sport_min",
    "calories",
    "humeur_0_5",
    "stress_0_5",
    "fc_repos"
]

X = df[features]
y = df["score"]

# ğŸ”¹ Normalisation
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ğŸ”¹ RÃ©gression (score)
model = LinearRegression()
model.fit(X_scaled, y)

# ğŸ”¹ DÃ©tection dâ€™anomalies (ML utile)
anomaly_model = IsolationForest(
    contamination=0.15,
    random_state=42
)
anomaly_model.fit(X_scaled)

# ğŸ”¹ Sauvegarde modÃ¨les
joblib.dump(model, "model_score.pkl")
joblib.dump(scaler, "scaler.pkl")
joblib.dump(anomaly_model, "anomaly.pkl")

print("âœ… ML entraÃ®nÃ© et sauvegardÃ©")
print("ğŸ“ Dataset exportÃ© : dataset_export.csv")
